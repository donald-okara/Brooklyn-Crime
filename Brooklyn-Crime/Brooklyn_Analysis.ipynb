{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brooklyn Crime "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phases\n",
    "1) Data Mining\n",
    "2) Data Exploration & Data Cleaning\n",
    "3) Feature Engineering \n",
    "4) Predictive Modeling \n",
    "5) Visualization & Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Data Mining**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "from geopy.geocoders import Nominatim\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "import math\n",
    "from datetime import datetime\n",
    "from shapely.geometry import Point\n",
    "import csv\n",
    "import os\n",
    "from sklearn.impute import SimpleImputer\n",
    "import contextily  as ctx\n",
    "\n",
    "from datetime import date\n",
    "from datetime import time\n",
    "from sodapy import Socrata\n",
    "\n",
    "import folium\n",
    "from folium import Choropleth, Circle, Marker\n",
    "from folium.plugins import HeatMap, MarkerCluster\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "from matplotlib import cm\n",
    "\n",
    "import powerbiclient\n",
    "from powerbiclient import Report, models\n",
    "\n",
    "\n",
    "#Ignore the highlighted \"Errors\". The editor has it's issues but they run perfectly fine.\n",
    "print(\"Libraries imported successfully...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "####Loading data  from city of new york API\n",
    "# Unauthenticated client only works with public data sets. Note 'None'\n",
    "# in place of application token, and no username or password:\n",
    "\n",
    "\n",
    "client = Socrata(\"data.cityofnewyork.us\", None)\n",
    "    \n",
    "# Example authenticated client (needed for non-public datasets)\n",
    "# client = Socrata(data.cityofnewyork.us,\n",
    "#                  MyAppToken\n",
    "#                  username=\\\"user@example.com\\\n",
    "#                  password=\\\"AFakePassword\\\")\n",
    "    \n",
    "# First 2000 results, returned as JSON from API \n",
    "# dictionaries by sodapy\n",
    "\n",
    "##Removing missing  values in Complaints_df\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPLAINTS\n",
    "query = f\"\"\"\n",
    "SELECT * \n",
    "\n",
    "WHERE boro_nm =\"BROOKLYN\"\n",
    "    AND susp_race IS NOT NULL\n",
    "    AND susp_sex IS NOT NULL\n",
    "    AND susp_age_group IS NOT NULL\n",
    "    AND cmplnt_to_dt  IS NOT NULL\n",
    "    AND cmplnt_to_tm IS NOT NULL\n",
    "    AND cmplnt_fr_dt IS NOT NULL\n",
    "    AND cmplnt_fr_tm IS NOT NULL\n",
    "    AND vic_age_group  IS NOT NULL\n",
    "    AND cmplnt_fr_dt\n",
    "BETWEEN '2022-01-01' AND '2022-12-31' \n",
    "\n",
    "LIMIT 100000\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "Complaints = client.get(\"5uac-w243\", query = query)\n",
    "    \n",
    "# Convert to pandas DataFrame \n",
    "Complaints_df = pd.DataFrame.from_records(Complaints)\n",
    "#By far the largest df This program can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zillow\n",
    "Zillow = pd.read_csv(r'D:\\Motherless Brooklyn\\Brooklyn-Crime\\zillow NY for-sale properties.csv')\n",
    "Zillow = Zillow.loc[Zillow.city.isin(['Brooklyn'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CENSUS\n",
    "query = f\"\"\"\n",
    "SELECT * \n",
    "\n",
    "WHERE borough =\"Brooklyn\"\n",
    "    \n",
    "LIMIT 100000\n",
    "\n",
    "\"\"\"\n",
    "Census = client.get(\"swpk-hqdp\", query = query)\n",
    "    \n",
    "# Convert to pandas DataFrame \n",
    "Census = pd.DataFrame.from_records(Census)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Data Cleaning and Data Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "#Columns list for Zillow\n",
    "\n",
    "count = 0\n",
    "for col in Zillow.columns:\n",
    "    print(col)\n",
    "    count+= 1\n",
    "\n",
    "print(\"Number of columns are: \",count,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns list for Complaints_df\n",
    "count = 0\n",
    "for col in Complaints_df.columns:\n",
    "    print(col)\n",
    "    count+= 1\n",
    "\n",
    "print(\"Number of columns are: \",count,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns list for Census\n",
    "count = 0\n",
    "for col in Census.columns:\n",
    "    print(col)\n",
    "    count+= 1\n",
    "\n",
    "print(\"Number of columns are: \",count,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Complaints_df.loc[:,['lat_lon']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        a) Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        i) Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of missing data points per column in Complaints_df\n",
    "missing_values_count_Complaints = Complaints_df.isnull().sum()\n",
    "\n",
    "# look at the # of missing points\n",
    "missing_values_count_Complaints\n",
    "\n",
    "##Relevant Null vallues dropped in mining via query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding weekdays\n",
    "Complaints_df[\"cmplnt_fr_dt\"]= Complaints_df['cmplnt_fr_dt'].astype('datetime64[ns]')\n",
    "Complaints_df.dtypes\n",
    "Complaints_df[\"Weekdays\"] = Complaints_df['cmplnt_fr_dt'].dt.dayofweek\n",
    "Complaints_df.loc[:,['cmplnt_fr_dt', 'Weekdays' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting locations into real numbers for Zillow\n",
    "\n",
    "\n",
    "dict_columns_type = {'longitude': float,\n",
    "                'latitude': float\n",
    "               }\n",
    "               \n",
    "   \n",
    "Zillow = Zillow.astype(dict_columns_type)\n",
    "Zillow.loc[:,['longitude', 'latitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of missing data points per column in Zillow\n",
    "missing_values_count_zillow = Zillow.isnull().sum()\n",
    "\n",
    "# look at the # of missing points\n",
    "missing_values_count_zillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of missing data points per column in Complaints_df\n",
    "missing_values_count_Census = Census.isnull().sum()\n",
    "\n",
    "# look at the # of missing points\n",
    "missing_values_count_Census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ii) Fixing Locations and precincts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting locations into real numbers for Complaints_df\n",
    "\n",
    "dict_columns_type = {'longitude': float,\n",
    "                'latitude': float\n",
    "               }\n",
    "   \n",
    "Complaints_df = Complaints_df.astype(dict_columns_type)\n",
    "Complaints_df.loc[:,['longitude', 'latitude']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ii.a) GeoData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precincts and Complaints_df\n",
    "precincts_mp = gpd.read_file(r\"D:\\Motherless Brooklyn\\Brooklyn-Crime\\Police Precincts\\geo_export_cd0a4750-fe4c-4415-9f05-3e7f0f353d91.shp\")\n",
    "\n",
    "precincts_mp.crs={'init': 'epsg:32630'}\n",
    "\n",
    "Complaints_mp = gpd.GeoDataFrame(Complaints_df, geometry=gpd.points_from_xy(Complaints_df.longitude, Complaints_df.latitude))\n",
    "Complaints_mp.crs = {'init': 'epsg:32630'}\n",
    "\n",
    "\n",
    "precincts_mp = precincts_mp.loc[precincts_mp.precinct.isin([60.0,\n",
    "    61.0,\n",
    "    62.0,\n",
    "    63.0,\n",
    "    66.0,\n",
    "    67.0,\n",
    "    68.0,\n",
    "    69.0,\n",
    "    70.0,\n",
    "    71.0,\n",
    "    72.0,\n",
    "    73.0,\n",
    "    75.0,\n",
    "    76.0,\n",
    "    77.0,\n",
    "    78.0,\n",
    "    79.0,\n",
    "    81.0,\n",
    "    83.0,\n",
    "    84.0,\n",
    "    88.0,\n",
    "    90.0,\n",
    "    94.0\n",
    "    ])].copy()\n",
    "\n",
    "precincts_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zillow\n",
    "print(\"{}% of addresses were geocoded!\".format(\n",
    "    (1 - sum(np.isnan(Zillow[\"latitude\"])) / len(Zillow)) * 100))\n",
    "\n",
    "# Drop Places that were not successfully geocoded\n",
    "Zillow = Zillow.loc[~np.isnan(Zillow[\"latitude\"])]\n",
    "Zillow_mp = gpd.GeoDataFrame(\n",
    "    Zillow, geometry=gpd.points_from_xy(Zillow.longitude, Zillow.latitude))\n",
    "Zillow_mp.crs = {'init': 'epsg:32630'}\n",
    "Zillow_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geocoding Census\n",
    "geolocator = Nominatim(user_agent=\"Don\")\n",
    "def my_geocoder(row):\n",
    "    try:\n",
    "        point = geolocator.geocode(row).point\n",
    "        return pd.Series({'latitude': point.latitude, 'longitude': point.longitude})\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "Census[['latitude', 'longitude']] = Census.apply(lambda x: my_geocoder(x['nta_name']), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}% of addresses were geocoded!\".format(\n",
    "    (1 - sum(np.isnan(Census[\"latitude\"])) / len(Census)) * 100))\n",
    "\n",
    "# Drop Places that were not successfully geocoded\n",
    "Census = Census.loc[~np.isnan(Census[\"latitude\"])]\n",
    "Census_mp = gpd.GeoDataFrame(\n",
    "    Census, geometry=gpd.points_from_xy(Census.longitude, Census.latitude))\n",
    "Census_mp.crs = {'init': 'epsg:32630'}\n",
    "Census_mp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ii.b) Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a map for Zillow_mp\n",
    "ax = precincts_mp.plot(figsize=(8,8), color='whitesmoke', linestyle=':', edgecolor='black')\n",
    "Zillow_mp.plot(markersize=1, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a map for Complaints_mp\n",
    "ax = precincts_mp.plot(figsize=(8,8), color='whitesmoke', linestyle=':', edgecolor='black')\n",
    "Complaints_mp.plot(markersize=1, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB/= The locations with no records of complaints or properties are mostly parks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ii.c) Merging with precincts_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining precinct with census\n",
    "Census_mp = gpd.sjoin(Census_mp, precincts_mp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using spatial join to assign precincts to Neighborhood\n",
    "Zillow_mp = gpd.sjoin(Zillow_mp, precincts_mp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping addr_pct_cd\n",
    "Complaints_df.drop('addr_pct_cd', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing addr_pct_cd with precincts\n",
    "Complaints_mp = gpd.sjoin(Complaints_mp, precincts_mp)\n",
    "\n",
    "Complaints_mp.dtypes\n",
    "#TODO: Separate categorical data and numeric data in Zillow_mp\n",
    "#TODO: Apply Neighborhood features to Complaints data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns list for Complaints_mp\n",
    "count = 0\n",
    "for col in Complaints_mp.columns:\n",
    "    print(col)\n",
    "    count+= 1\n",
    "\n",
    "print(\"Number of columns are: \",count,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns list for Zillow_mp\n",
    "count = 0\n",
    "for col in Zillow_mp.columns:\n",
    "    print(col)\n",
    "    count+= 1\n",
    "\n",
    "print(\"Number of columns are: \",count,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns list for Census_mp\n",
    "count = 0\n",
    "for col in Census_mp.columns:\n",
    "    print(col)\n",
    "    count+= 1\n",
    "\n",
    "print(\"Number of columns are: \",count,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Complaints_mp['cmplnt_fr_tm'] = Complaints_mp['cmplnt_fr_tm'].astype('datetime64[ns]')\n",
    "Complaints_mp['cmplnt_to_dt'] = pd.to_datetime(Complaints_mp['cmplnt_to_dt'])\n",
    "Complaints_mp['cmplnt_to_tm'] = Complaints_mp['cmplnt_to_tm'].astype('datetime64[ns]')\n",
    "Complaints_mp.loc[:,['cmplnt_fr_dt','cmplnt_fr_tm','cmplnt_to_tm','cmplnt_to_dt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Complaints_mp.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    b) Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    i) Complaints_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Complaints_mp['cmplnt_dt'] = Complaints_mp.cmplnt_fr_dt.dt.date\n",
    "Complaints_mp['cmplnt_tm'] = Complaints_mp.cmplnt_fr_tm.dt.hour\n",
    "Complaints_mp.loc[:,['cmplnt_dt','cmplnt_tm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = sns.color_palette()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "data = Complaints_mp.groupby('cmplnt_dt').count().iloc[:, 0]\n",
    "sns.kdeplot(data=data, shade=True)\n",
    "plt.axvline(x=data.median(), ymax=0.95, linestyle='--', color=col[1])\n",
    "plt.annotate(\n",
    "    'Median: ' + str(data.median()),\n",
    "    xy=(data.median(), 0.004),\n",
    "    xytext=(200, 0.005))\n",
    "plt.title(\n",
    "    'Distribution of number of incidents per day', fontdict={'fontsize': 16})\n",
    "plt.xlabel('Incidents')\n",
    "plt.ylabel('Density')\n",
    "plt.legend().remove()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Incidents per hour\n",
    "data = Complaints_mp.groupby('cmplnt_tm').count().iloc[:, 0]\n",
    "data = data.reindex([\n",
    "    0, 1, 2, 3, 4, 5,\n",
    "    6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    ax = sns.barplot(\n",
    "        data.index, (data.values / data.values.sum()) * 100,\n",
    "        orient='v',\n",
    "        palette=cm.ScalarMappable(cmap='Reds').to_rgba(data.values))\n",
    "\n",
    "plt.title('Incidents per hour', fontdict={'fontsize': 16})\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Incidents (%)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Incidents per Weekday\n",
    "data = Complaints_mp.groupby('Weekdays').count().iloc[:, 0]\n",
    "data = data.reindex([\n",
    "    0, 1, 2, 3, 4, 5,\n",
    "    6\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    ax = sns.barplot(\n",
    "        data.index, \n",
    "        (data.values / data.values.sum()) * 100,\n",
    "        orient='v',\n",
    "        palette=cm.ScalarMappable(cmap='Reds').to_rgba(data.values))\n",
    "\n",
    "plt.title('Incidents per Weekday', fontdict={'fontsize': 16})\n",
    "plt.xlabel('Weekday')\n",
    "plt.ylabel('Incidents (%)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Complaints_mp.groupby('ofns_desc').count().iloc[:, 0].sort_values(\n",
    "    ascending=False)\n",
    "data = data.reindex(np.append(np.delete(data.index, 1), 'OTHER OFFENSES'))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    ax = sns.barplot(\n",
    "        (data.values / data.values.sum()) * 100,\n",
    "        data.index,\n",
    "        orient='h',\n",
    "        palette=\"Reds_r\")\n",
    "\n",
    "plt.title('Incidents per Crime Category', fontdict={'fontsize': 16})\n",
    "plt.xlabel('Incidents (%)')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#TODO: Get sum for each precinct (Complaints, population)\n",
    "#TODO: Get real estate value for each precinct\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precincts_m1 = precincts_mp[[\"precinct\", \"geometry\"]].set_index(\"precinct\")\n",
    "plot_dict = Complaints_mp.precinct.value_counts()\n",
    "plot_dict.to_frame(name=\"prenct_density\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base map\n",
    "Heatmap_precincts = folium.Map(location=[40.625,-73.95], tiles='cartodbpositron', zoom_start=12)\n",
    "\n",
    "# Add a heatmap to the base map\n",
    "HeatMap(data=Complaints_mp[['latitude', 'longitude']], radius=10).add_to(Heatmap_precincts)\n",
    "\n",
    "# Display the map\n",
    "Heatmap_precincts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NewEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21a581218586d279581d34e7b0e3901713820e8aea20b11f3e094bdc5a18c1df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
