{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Brooklyn Crime** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Phases*\n",
    "1) Data Mining\n",
    "2) Data Exploration & Data Cleaning\n",
    "3) Feature Engineering \n",
    "4) Predictive Modeling \n",
    "5) Visualization & Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Data Mining**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "from geopy.geocoders import Nominatim\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import geoplot as gplt\n",
    "\n",
    "import math\n",
    "from datetime import datetime\n",
    "from shapely.geometry import Point\n",
    "import csv\n",
    "import os\n",
    "from sklearn.impute import SimpleImputer\n",
    "import contextily  as ctx\n",
    "\n",
    "from datetime import date\n",
    "from datetime import time\n",
    "from sodapy import Socrata\n",
    "\n",
    "import folium\n",
    "from folium import Choropleth, Circle, Marker\n",
    "from folium.plugins import HeatMap, MarkerCluster\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "from matplotlib import cm\n",
    "\n",
    "import powerbiclient\n",
    "from powerbiclient import Report, models\n",
    "\n",
    "\n",
    "print(\"Libraries imported successfully...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "####Loading data  from city of new york API\n",
    "# Unauthenticated client only works with public data sets. Note 'None'\n",
    "# in place of application token, and no username or password:\n",
    "\n",
    "\n",
    "client = Socrata(\"data.cityofnewyork.us\", None)\n",
    "    \n",
    "# Example authenticated client (needed for non-public datasets)\n",
    "# client = Socrata(data.cityofnewyork.us,\n",
    "#                  MyAppToken\n",
    "#                  username=\\\"user@example.com\\\n",
    "#                  password=\\\"AFakePassword\\\")\n",
    "    \n",
    "# First specified number of results, returned as JSON from API \n",
    "# dictionaries by sodapy\n",
    "\n",
    "##Removing missing  values in Complaints_df\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPLAINTS\n",
    "query = f\"\"\"\n",
    "SELECT * \n",
    "\n",
    "WHERE boro_nm =\"BROOKLYN\"\n",
    "    AND susp_race IS NOT NULL\n",
    "    AND susp_sex IS NOT NULL\n",
    "    AND susp_age_group IS NOT NULL\n",
    "    AND cmplnt_to_dt  IS NOT NULL\n",
    "    AND cmplnt_to_tm IS NOT NULL\n",
    "    AND cmplnt_fr_dt IS NOT NULL\n",
    "    AND cmplnt_fr_tm IS NOT NULL\n",
    "    AND vic_age_group  IS NOT NULL\n",
    "    AND cmplnt_fr_dt\n",
    "BETWEEN '2022-01-01' AND '2022-12-31' \n",
    "\n",
    "LIMIT 100000\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "Complaints = client.get(\"5uac-w243\", query = query)\n",
    "    \n",
    "# Convert to pandas DataFrame \n",
    "Complaints_df = pd.DataFrame.from_records(Complaints)\n",
    "#By far the largest df This program can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zillow\n",
    "Zillow = pd.read_csv(r'D:\\Motherless Brooklyn\\Brooklyn-Crime\\zillow NY for-sale properties.csv')\n",
    "Zillow = Zillow.loc[Zillow.city.isin(['Brooklyn'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CENSUS\n",
    "query = f\"\"\"\n",
    "SELECT * \n",
    "\n",
    "WHERE borough =\"Brooklyn\"\n",
    "    \n",
    "LIMIT 100000\n",
    "\n",
    "\"\"\"\n",
    "Census = client.get(\"swpk-hqdp\", query = query)\n",
    "    \n",
    "# Convert to pandas DataFrame \n",
    "Census = pd.DataFrame.from_records(Census)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Data Cleaning and Data Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "#Columns list for Zillow\n",
    "\n",
    "count = 0\n",
    "for col in Zillow.columns:\n",
    "    print(col)\n",
    "    count+= 1\n",
    "\n",
    "print(\"Number of columns are: \",count,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns list for Complaints_df\n",
    "count = 0\n",
    "for col in Complaints_df.columns:\n",
    "    print(col)\n",
    "    count+= 1\n",
    "\n",
    "print(\"Number of columns are: \",count,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns list for Census\n",
    "count = 0\n",
    "for col in Census.columns:\n",
    "    print(col)\n",
    "    count+= 1\n",
    "\n",
    "print(\"Number of columns are: \",count,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        a) Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        i) Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of missing data points per column in Complaints_df\n",
    "missing_values_count_Complaints = Complaints_df.isnull().sum()\n",
    "\n",
    "# look at the # of missing points\n",
    "missing_values_count_Complaints\n",
    "\n",
    "##Relevant Null vallues dropped in mining via query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding weekdays\n",
    "Complaints_df[\"cmplnt_fr_dt\"]= Complaints_df['cmplnt_fr_dt'].astype('datetime64[ns]')\n",
    "Complaints_df.dtypes\n",
    "Complaints_df[\"Weekdays\"] = Complaints_df['cmplnt_fr_dt'].dt.dayofweek\n",
    "Complaints_df.loc[:,['cmplnt_fr_dt', 'Weekdays' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of missing data points per column in Zillow\n",
    "missing_values_count_zillow = Zillow.isnull().sum()\n",
    "\n",
    "# look at the # of missing points\n",
    "missing_values_count_zillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of missing data points per column in Complaints_df\n",
    "missing_values_count_Census = Census.isnull().sum()\n",
    "\n",
    "# look at the # of missing points\n",
    "missing_values_count_Census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ii) Fixing Locations and precincts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting locations into real numbers for Zillow\n",
    "dict_columns_type = {'longitude': float,\n",
    "                'latitude': float\n",
    "               }\n",
    "               \n",
    "   \n",
    "Zillow = Zillow.astype(dict_columns_type)\n",
    "Zillow.loc[:,['longitude', 'latitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting locations into real numbers for Complaints_df\n",
    "\n",
    "dict_columns_type = {'longitude': float,\n",
    "                'latitude': float\n",
    "               }\n",
    "   \n",
    "Complaints_df = Complaints_df.astype(dict_columns_type)\n",
    "Complaints_df.loc[:,['longitude', 'latitude']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ii.a) GeoData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precincts and Complaints_df\n",
    "precincts_mp = gpd.read_file(r\"D:\\Motherless Brooklyn\\Brooklyn-Crime\\Police Precincts\\geo_export_cd0a4750-fe4c-4415-9f05-3e7f0f353d91.shp\")\n",
    "\n",
    "precincts_mp.crs={'init': 'epsg:32630'}\n",
    "\n",
    "Complaints_mp = gpd.GeoDataFrame(Complaints_df, geometry=gpd.points_from_xy(Complaints_df.longitude, Complaints_df.latitude))\n",
    "Complaints_mp.crs = {'init': 'epsg:32630'}\n",
    "\n",
    "\n",
    "precincts_mp = precincts_mp.loc[precincts_mp.precinct.isin([60.0,\n",
    "    61.0,\n",
    "    62.0,\n",
    "    63.0,\n",
    "    66.0,\n",
    "    67.0,\n",
    "    68.0,\n",
    "    69.0,\n",
    "    70.0,\n",
    "    71.0,\n",
    "    72.0,\n",
    "    73.0,\n",
    "    75.0,\n",
    "    76.0,\n",
    "    77.0,\n",
    "    78.0,\n",
    "    79.0,\n",
    "    81.0,\n",
    "    83.0,\n",
    "    84.0,\n",
    "    88.0,\n",
    "    90.0,\n",
    "    94.0\n",
    "    ])].copy()\n",
    "\n",
    "precincts_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting Zillow to a gpd\n",
    "print(\"{}% of addresses were geocoded!\".format(\n",
    "    (1 - sum(np.isnan(Zillow[\"latitude\"])) / len(Zillow)) * 100))\n",
    "\n",
    "# Drop Places that were not successfully geocoded\n",
    "Zillow = Zillow.loc[~np.isnan(Zillow[\"latitude\"])]\n",
    "Zillow_mp = gpd.GeoDataFrame(\n",
    "    Zillow, geometry=gpd.points_from_xy(Zillow.longitude, Zillow.latitude))\n",
    "Zillow_mp.crs = {'init': 'epsg:32630'}\n",
    "Zillow_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geocoding Census\n",
    "geolocator = Nominatim(user_agent=\"Don\")\n",
    "def my_geocoder(row):\n",
    "    try:\n",
    "        point = geolocator.geocode(row).point\n",
    "        return pd.Series({'latitude': point.latitude, 'longitude': point.longitude})\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "Census[['latitude', 'longitude']] = Census.apply(lambda x: my_geocoder(x['nta_name']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting Census to a gpd\n",
    "print(\"{}% of addresses were geocoded!\".format(\n",
    "    (1 - sum(np.isnan(Census[\"latitude\"])) / len(Census)) * 100))\n",
    "\n",
    "# Drop Places that were not successfully geocoded\n",
    "Census = Census.loc[~np.isnan(Census[\"latitude\"])]\n",
    "Census_mp = gpd.GeoDataFrame(\n",
    "    Census, geometry=gpd.points_from_xy(Census.longitude, Census.latitude))\n",
    "Census_mp.crs = {'init': 'epsg:32630'}\n",
    "Census_mp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ii.b) Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a map for Zillow_mp\n",
    "ax = precincts_mp.plot(figsize=(8,8), color='whitesmoke', linestyle=':', edgecolor='black')\n",
    "Zillow_mp.plot(markersize=1, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a map for Complaints_mp\n",
    "ax = precincts_mp.plot(figsize=(8,8), color='whitesmoke', linestyle=':', edgecolor='black')\n",
    "Complaints_mp.plot(markersize=1, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB/= The locations with no records of complaints or properties are mostly parks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ii.c) Merging with precincts_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining precinct with census\n",
    "Census_mp = gpd.sjoin(Census_mp, precincts_mp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using spatial join to assign precincts to Neighborhood\n",
    "Zillow_mp = gpd.sjoin(Zillow_mp, precincts_mp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping addr_pct_cd\n",
    "Complaints_df.drop('addr_pct_cd', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing addr_pct_cd with precincts\n",
    "Complaints_mp = gpd.sjoin(Complaints_mp, precincts_mp)\n",
    "\n",
    "Complaints_mp.dtypes\n",
    "#TODO: Separate categorical data and numeric data in Zillow_mp\n",
    "##DONE\n",
    "\n",
    "#TODO: Apply Neighborhood features to Complaints data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns list for Complaints_mp\n",
    "count = 0\n",
    "for col in Complaints_mp.columns:\n",
    "    print(col)\n",
    "    count+= 1\n",
    "\n",
    "print(\"Number of columns are: \",count,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns list for Zillow_mp\n",
    "count = 0\n",
    "for col in Zillow_mp.columns:\n",
    "    print(col)\n",
    "    count+= 1\n",
    "\n",
    "print(\"Number of columns are: \",count,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns list for Census_mp\n",
    "count = 0\n",
    "for col in Census_mp.columns:\n",
    "    print(col)\n",
    "    count+= 1\n",
    "\n",
    "print(\"Number of columns are: \",count,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To datetime64\n",
    "Complaints_mp['cmplnt_fr_tm'] = Complaints_mp['cmplnt_fr_tm'].astype('datetime64[ns]')\n",
    "Complaints_mp['cmplnt_to_dt'] = pd.to_datetime(Complaints_mp['cmplnt_to_dt'])\n",
    "Complaints_mp['cmplnt_to_tm'] = Complaints_mp['cmplnt_to_tm'].astype('datetime64[ns]')\n",
    "Complaints_mp.loc[:,['cmplnt_fr_dt','cmplnt_fr_tm','cmplnt_to_tm','cmplnt_to_dt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Complaints_mp.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    b) Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    i) Complaints_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Complaints_mp['cmplnt_dt'] = Complaints_mp.cmplnt_fr_dt.dt.date\n",
    "Complaints_mp['cmplnt_tm'] = Complaints_mp.cmplnt_fr_tm.dt.hour\n",
    "Complaints_mp.loc[:,['cmplnt_dt','cmplnt_tm']]\n",
    "Complaints_mp.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precincts_m1 = precincts_mp[[\"precinct\", \"geometry\"]].set_index(\"precinct\")\n",
    "precincts_m1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of crimes in each police district\n",
    "plot_prenct = Complaints_mp.precinct.value_counts()\n",
    "plot_prenct.head()\n",
    "Complaints_mp.loc[:,['longitude','latitude']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base map\n",
    "Chloropleth_prenct = folium.Map(location=[40.634565,-73.928086], tiles='cartodbpositron', zoom_start=12)\n",
    "\n",
    "# Add a choropleth map to the base map\n",
    "Choropleth(geo_data=precincts_m1.__geo_interface__, \n",
    "           data=plot_prenct, \n",
    "           key_on=\"feature.id\", \n",
    "           fill_color='YlGnBu', \n",
    "           legend_name='Major criminal incidents (Jan-Aug 2018)'\n",
    "          ).add_to(Chloropleth_prenct)\n",
    "\n",
    "# Display the map\n",
    "Chloropleth_prenct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base map\n",
    "Heatmap_crime_density= folium.Map(location=[40.625,-73.95], tiles='cartodbpositron', zoom_start=12)\n",
    "\n",
    "# Add a heatmap to the base map\n",
    "HeatMap(data=Complaints_mp[['latitude', 'longitude']], radius=10).add_to(Heatmap_crime_density)\n",
    "\n",
    "# Display the map\n",
    "Heatmap_crime_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of number of incidents per day\n",
    "col = sns.color_palette()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "data = Complaints_mp.groupby('cmplnt_dt').count().iloc[:, 0]\n",
    "sns.kdeplot(data=data, shade=True)\n",
    "plt.axvline(x=data.median(), ymax=0.95, linestyle='--', color=col[1])\n",
    "plt.annotate(\n",
    "    'Median: ' + str(data.median()),\n",
    "    xy=(data.median(), 0.004),\n",
    "    xytext=(200, 0.005))\n",
    "plt.title(\n",
    "    'Distribution of number of incidents per day', fontdict={'fontsize': 16})\n",
    "plt.xlabel('Incidents')\n",
    "plt.ylabel('Density')\n",
    "plt.legend().remove()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Incidents per hour\n",
    "data = Complaints_mp.groupby('cmplnt_tm').count().iloc[:, 0]\n",
    "data = data.reindex([\n",
    "    0, 1, 2, 3, 4, 5,\n",
    "    6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    ax = sns.barplot(\n",
    "        data.index, (data.values / data.values.sum()) * 100,\n",
    "        orient='v',\n",
    "        palette=cm.ScalarMappable(cmap='Reds').to_rgba(data.values))\n",
    "\n",
    "plt.title('Incidents per hour', fontdict={'fontsize': 16})\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Incidents (%)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Incidents per Weekday\n",
    "data = Complaints_mp.groupby('Weekdays').count().iloc[:, 0]\n",
    "data = data.reindex([\n",
    "    0, 1, 2, 3, 4, 5,\n",
    "    6\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    ax = sns.barplot(\n",
    "        data.index, \n",
    "        (data.values / data.values.sum()) * 100,\n",
    "        orient='v',\n",
    "        palette=cm.ScalarMappable(cmap='Reds').to_rgba(data.values))\n",
    "\n",
    "plt.title('Incidents per Weekday', fontdict={'fontsize': 16})\n",
    "plt.xlabel('Weekday')\n",
    "plt.ylabel('Incidents (%)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking most popular crimes\n",
    "data = Complaints_mp.groupby('ofns_desc').count().iloc[:, 0].sort_values(\n",
    "    ascending=False)\n",
    "data = data.reindex(np.append(np.delete(data.index, 1), 'OTHER OFFENSES'))\n",
    "\n",
    "data\n",
    "\n",
    "#TODO: Get real estate value for each precinct\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lOCATION OF OCCURENCE\n",
    "data = Complaints_mp.groupby('loc_of_occur_desc').count().iloc[:, 0]\n",
    "data = data.reindex([\n",
    "    'REAR OF', 'OPPOSITE OF', 'INSIDE', '(null)'\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    ax = sns.barplot(\n",
    "        data.index, \n",
    "        (data.values / data.values.sum()) * 100,\n",
    "        orient='v',\n",
    "        palette=cm.ScalarMappable(cmap='Reds').to_rgba(data.values))\n",
    "\n",
    "plt.title('lOCATION OF OCCURENCE', fontdict={'fontsize': 16})\n",
    "plt.xlabel('lOCATION')\n",
    "plt.ylabel('Incidents (%)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Majority of the incidents happened inside*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution by suspect race\n",
    "data = Complaints_mp.groupby('susp_race').count().iloc[:, 0].sort_values(\n",
    "    ascending=False)\n",
    "data = data.reindex(np.append(np.delete(data.index, 1), 'OTHER'))\n",
    "\n",
    "data\n",
    "\n",
    "#TODO: Get real estate value for each precinct\n",
    "##DONE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution by suspect race visualization\n",
    "data = Complaints_mp.groupby('susp_race').count().iloc[:, 0]\n",
    "data = data.reindex([\n",
    "    'BLACK', 'WHITE HISPANIC', 'WHITE', 'ASIAN / PACIFIC ISLANDER','BLACK HISPANIC','AMERICAN INDIAN/ALASKAN NATIVE','(null)'\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    ax = sns.barplot(\n",
    "        data.index, \n",
    "        (data.values / data.values.sum()) * 100,\n",
    "        orient='v',\n",
    "        palette=cm.ScalarMappable(cmap='Reds').to_rgba(data.values))\n",
    "\n",
    "plt.title('Suspect race', fontdict={'fontsize': 16})\n",
    "plt.xlabel('Suspects')\n",
    "plt.ylabel('Incidents (%)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution by victim race visualization\n",
    "data = Complaints_mp.groupby('vic_race').count().iloc[:, 0]\n",
    "data = data.reindex([\n",
    "    'BLACK', 'WHITE HISPANIC', 'WHITE', 'ASIAN / PACIFIC ISLANDER','BLACK HISPANIC','AMERICAN INDIAN/ALASKAN NATIVE','(null)'\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    ax = sns.barplot(\n",
    "        data.index, \n",
    "        (data.values / data.values.sum()) * 100,\n",
    "        orient='v',\n",
    "        palette=cm.ScalarMappable(cmap='Reds').to_rgba(data.values))\n",
    "\n",
    "plt.title('Victim race', fontdict={'fontsize': 16})\n",
    "plt.xlabel('Victim')\n",
    "plt.ylabel('Incidents (%)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution by suspect sex visualization\n",
    "data = Complaints_mp.groupby('susp_sex').count().iloc[:, 0]\n",
    "data = data.reindex([\n",
    "    'M', 'F', 'U','(null)'\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    ax = sns.barplot(\n",
    "        data.index, \n",
    "        (data.values / data.values.sum()) * 100,\n",
    "        orient='v',\n",
    "        palette=cm.ScalarMappable(cmap='Reds').to_rgba(data.values))\n",
    "\n",
    "plt.title('Suspect sex', fontdict={'fontsize': 16})\n",
    "plt.xlabel('Suspects')\n",
    "plt.ylabel('Incidents (%)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution by Victim sex\n",
    "data = Complaints_mp.groupby('vic_sex').count().iloc[:, 0].sort_values(\n",
    "    ascending=False)\n",
    "data = data.reindex(np.append(np.delete(data.index, 1), 'OTHER'))\n",
    "\n",
    "data\n",
    "\n",
    "#TODO:Get real estate value for each precinct\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution by victim sex visualization\n",
    "data = Complaints_mp.groupby('vic_sex').count().iloc[:, 0]\n",
    "data = data.reindex([\n",
    "    'L', 'F', 'D','E'\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    ax = sns.barplot(\n",
    "        data.index, \n",
    "        (data.values / data.values.sum()) * 100,\n",
    "        orient='v',\n",
    "        palette=cm.ScalarMappable(cmap='Reds').to_rgba(data.values))\n",
    "\n",
    "plt.title('Victim sex', fontdict={'fontsize': 16})\n",
    "plt.xlabel('Victim')\n",
    "plt.ylabel('Incidents (%)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Victimâ€™s Sex Description**\n",
    "D=Business/Organization, \n",
    "E=PSNY/People of the State of New York, \n",
    "F=Female, \n",
    "M=Male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precincts_m1 = precincts_mp[[\"precinct\", \"geometry\"]].set_index(\"precinct\")\n",
    "plot_dict = Complaints_mp.precinct.value_counts()\n",
    "plot_dict.to_frame(name=\"prenct_density\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geographic Density of Different Crimes\n",
    "crimes_cat = Complaints_mp['ofns_desc'].unique().tolist()\n",
    "\n",
    "bk_land = precincts_mp.unary_union\n",
    "bk_land = gpd.GeoDataFrame(gpd.GeoSeries(bk_land), crs={'init':'epsg:32630'})\n",
    "bk_land = bk_land.rename(columns={0:'geometry'}).set_geometry('geometry')\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, sharex=True, sharey=True, figsize=(12,12))\n",
    "for i , crime in enumerate(np.random.choice(crimes_cat, size=9, replace=False)):\n",
    "    data = Complaints_mp.loc[Complaints_mp['ofns_desc'] == crime]\n",
    "    ax = fig.add_subplot(3, 3, i+1)\n",
    "    gplt.kdeplot(data,\n",
    "                 shade=True,\n",
    "                 shade_lowest=False,\n",
    "                 clip = bk_land.geometry,\n",
    "                 cmap='Reds',\n",
    "                 ax=ax)\n",
    "    gplt.polyplot(bk_land, ax=ax)\n",
    "    ax.set_title(crime) \n",
    "plt.suptitle('Geographic Density of Different Crimes')\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average number of incidents per hour for various crimes\n",
    "data = Complaints_mp.groupby(['cmplnt_tm', 'index_right', 'ofns_desc'],\n",
    "                     as_index=False).count().iloc[:, :4]\n",
    "data.rename(columns={'index_right': 'Incidents'}, inplace=True)\n",
    "data = data.groupby(['cmplnt_tm', 'ofns_desc'], as_index=False).mean()\n",
    "data = data.loc[data['ofns_desc'].isin(\n",
    "    ['ROBBERY', 'KIDNAPPING', 'PETIT LARCENY', 'FELONY ASSAULT', 'POSSESSION OF STOLEN PROPERTY','CRIMINAL TRESPASS','GRAND LARCENY OF MOTOR VEHICLE'])]\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "ax = sns.lineplot(x='cmplnt_tm', y='Incidents', data=data, hue='ofns_desc')\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.15), ncol=6)\n",
    "plt.suptitle('Average number of incidents per hour')\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ii) Zillow_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zillow_mp.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating categorical variables with numerical values. Location to be included in both.\n",
    "Zillow_cat = Zillow_mp.loc[:,['city', 'state','longitude','latitude','land_space_unit', 'property_type','property_status','precinct', 'geometry']]\n",
    "Zillow_num = Zillow_mp.loc[:,['price', 'bedroom_number', 'bathroom_number', 'price_per_unit', 'living_space', 'land_space']]\n",
    "Zillow_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distributions for all numeric variables \n",
    "for i in Zillow_num.columns:\n",
    "    plt.hist(Zillow_num[i])\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zillow_num correlation\n",
    "print(Zillow_num.corr())\n",
    "sns.heatmap(Zillow_num.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Census_mp.dtypes\n",
    "#Census_mp by population and merge with precincts_mp\n",
    "##DONE\n",
    "\n",
    "Zillow_mp.dtypes\n",
    "#TODO:Group Zillow_mp by price_per_unit and merge with precincts_mp\n",
    "##DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    a) Applying features to precincts_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding population to precincts_mp\n",
    "Census_prenct = Census_mp.groupby('precinct').population.mean()\n",
    "Census_prenct = Census_prenct.to_frame()\n",
    "Census_prenct = Census_prenct.rename(columns= {1: 'population'})\n",
    "precincts_mp = precincts_mp.merge(Census_prenct, on='precinct')\n",
    "precincts_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding price_per_unit to precincts_mp\n",
    "Zillow_prenct = Zillow_mp.groupby('precinct').price_per_unit.mean()\n",
    "Zillow_prenct = Zillow_prenct.to_frame()\n",
    "Zillow_prenct = Zillow_prenct.rename(columns= {1: 'price_per_unit'})\n",
    "precincts_mp = precincts_mp.merge(Zillow_prenct, on='precinct')\n",
    "\n",
    "precincts_mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    a) i)Analysis on precincts (price per unit & population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('NewEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21a581218586d279581d34e7b0e3901713820e8aea20b11f3e094bdc5a18c1df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
